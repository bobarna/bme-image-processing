{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_ASk2EUTQe1"
   },
   "source": [
    "# Optical character recognition (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad93UD1tcmnC"
   },
   "source": [
    "# Previous work\n",
    "\n",
    "Survey of some of the previously developed OCR software products and technologies.\n",
    "\n",
    "\n",
    "- **CuneiForm**\n",
    "    - by Russian software company Cognitive Technologies\n",
    "    - **Open-source**\n",
    "    - [Link](https://www.linuxlinks.com/cuneiform/)\n",
    "\n",
    "\n",
    "- **Tesseract**\n",
    "    - Originally developed by Hewlett-Packard as proprietary software in the 1980s\n",
    "    - Supervised by Google.\n",
    "    - **Apache License**\n",
    "    - [Link](https://github.com/tesseract-ocr)\n",
    "\n",
    "- **GdPicture OCR SDK**\n",
    "    - GdPicture includes an Optical Character Recognition engine to develop any kind of application requiring OCR technology.\n",
    "    - **Not open-source!**\n",
    "    - [Link](https://www.gdpicture.com/ocr-sdk/)\n",
    "\n",
    "\n",
    "- **Transym**\n",
    "    - TOCR is a one of the most sophisticated OCR software packages on the market, specifically designed for ease of integration. With a free API and attractive volume pricing, it is designed for system integrators.\n",
    "    - **Not open-source!**\n",
    "    - [Link](https://transym.com/)\n",
    "\n",
    "\n",
    "- **Computer Vision**\n",
    "    - by Microsoft\n",
    "    - An AI service that analyzes content in images and video\n",
    "    - Boost content discoverability, automate text extraction, analyze video in real time, and create products that more people can use by embedding cloud vision capabilities in your apps with Computer Vision, part of Azure Cognitive Services. Use visual data processing to label content with objects and concepts, extract text, generate image descriptions, moderate content, and understand people's movement in physical spaces. No machine learning expertise is required.\n",
    "\n",
    "- **Azure service**\n",
    "    - [Link](https://azure.microsoft.com/en-us/products/cognitive-services/computer-vision/#overview)\n",
    "\n",
    "- **Google AI**\n",
    "    - [Link](https://ai.google/tools/#developers)\n",
    "\n",
    "- **Amazon Textract**\n",
    "    - \"Automatically extract printed text, handwriting, and data from any document\"\n",
    "\n",
    "- **AWS component**\n",
    "    - [Link](https://aws.amazon.com/textract/)\n",
    "\n",
    "\n",
    "- **Kadmos**\n",
    "    - from reRecognition\n",
    "    - KADMOS is an ICR and OCR technology for developers built on unique “discriminatory entropy”methodology that does not depend on dictionaries. KADMOS offers exceptionally fast processing speeds in over 200 languages for both hand-written and machine printed text.\n",
    "    - Provided as a feature rich SDK, KADMOS can be integrated into the most sophisticated applications where mission critical levels of accuracy and speed are required.\n",
    "    - KADMOS is used extensively in document management, finance, healthcare, education, government and defence applications around the world and selected by developers for its unique capabilities.\n",
    "    - **Not open-source!**\n",
    "    - [Link](https://rerecognition.com/products/)\n",
    "\n",
    "- **Mindee**\n",
    "    - Python OCR SDK\n",
    "    - Supports invoice, passport, receipt OCR APIs and custom-built API from the API Builder.\n",
    "    - **MIT license**\n",
    "    - [Getting started](https://developers.mindee.com/docs/python-getting-started)\n",
    "    - [Source code](https://github.com/mindee/mindee-api-python)\n",
    "\n",
    "- **ocr.pytorch**\n",
    "    - An open-source project on GitHub\n",
    "    - Pure pytorch implemented OCR project including text detection and recognition.\n",
    "    - **MIT license**\n",
    "    - [Repository](https://github.com/courao/ocr.pytorch)\n",
    "\n",
    "- **TextRecognitionDataGenerator**\n",
    "    - A synthetic data generator for text recognition\n",
    "    - **MIT license**\n",
    "    - [Link](https://github.com/Belval/TextRecognitionDataGenerator)\n",
    "\n",
    "- **License plate font**\n",
    "    - .ttf font\n",
    "    - open for commercial use\n",
    "    - [Link](https://www.1001fonts.com/license-plates-fonts.html)\n",
    "\n",
    "- **B. Shi, X. Bai and C. Yao**\n",
    "    - B. Shi, X. Bai and C. Yao, \"An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 39, no. 11, pp. 2298-2304, 1 Nov. 2017, doi: 10.1109/TPAMI.2016.2646371.\n",
    "     - [Link](https://ieeexplore.ieee.org/abstract/document/7801919?casa_token=l7alCR-iNckAAAAA:XjdU8cR5KEKqRJKS48UZSxoyXqM5LGl4llw-HUIh9UbSAiK9v3zPyD9gYvwjsngkrRW-HEh1_Q)\n",
    "\n",
    "\n",
    "- **Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition**\n",
    "    - Max Jaderberg, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman\n",
    "    - [Link](https://arxiv.org/abs/1406.2227)\n",
    "\n",
    "- **Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks**\n",
    "    - Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber. 2006. Connectionist temporal classifiation: labelling unsegmented sequence data with recurrent neural networks. In Proceedings of the 23rd international conference on Machine learning (ICML '06). Association for Computing Machinery, New York, NY, USA, 369–376. https://doi.org/10.1145/1143844.1143891\n",
    "    - [Link](https://dl.acm.org/doi/abs/10.1145/1143844.1143891?casa_token=e19selHVFKsAAAAA:mrb7JOGyGF84MfHGUcpvhE1AzuC-_fUKIYI-yHsZa8wpuyR0ld5xzCTmUNT0hU3xgi6aJyXkA9Zn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2640Kj5ClFp_"
   },
   "source": [
    "# Learning materials for building Pytorch OCR application\n",
    "- [Building a custom OCR using pytorch](https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html)\n",
    "-[I need advice for a OCR project](https://discuss.pytorch.org/t/i-need-advice-for-a-ocr-project/113087)\n",
    "-[Simon Z. Python kurzus](https://theflyingpiano99.github.io/PythonBeginnerCourse/index.html)\n",
    "-[Pytorch official tutorials](https://pytorch.org/tutorials/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LLYTENflsSx"
   },
   "source": [
    "# OCR study\n",
    "\n",
    "In this section we make notes about the architecture of the OCR system under design.\n",
    "The ideas in this section originate mainly from [Building a custom OCR using pytorch](https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html#setting-up-the-data).\n",
    "\n",
    "##Setting up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lPsMnKgrPHc",
    "outputId": "92a625a0-2880-4efc-a2fe-aec5e69830d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n",
      "Collecting trdg\n",
      "  Downloading trdg-1.8.0-py3-none-any.whl (98.6 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/98.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:27\u001b[0m:27\u001b[0m^C\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/98.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:27\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (9.2.0)\n",
      "Collecting torch_utils\n",
      "  Downloading torch-utils-0.1.2.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from torch_utils) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch->torch_utils) (4.4.0)\n",
      "Building wheels for collected packages: torch_utils\n",
      "  Building wheel for torch_utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch_utils: filename=torch_utils-0.1.2-py3-none-any.whl size=6187 sha256=d10bbff618416650473227adbb72022225e5ff1ae85c0e044535f16b0c037c78\n",
      "  Stored in directory: /Users/bobarna/Library/Caches/pip/wheels/39/08/27/156ba3a830c518bfc69f5841f203a467ae1732c9c7ca0489bf\n",
      "Successfully built torch_utils\n",
      "Installing collected packages: torch_utils\n",
      "Successfully installed torch_utils-0.1.2\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from torchvision) (1.23.2)\n",
      "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.10/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Collecting pytorch_wrapper\n",
      "  Downloading pytorch-wrapper-1.1.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.14 in /usr/local/lib/python3.10/site-packages (from pytorch_wrapper) (1.23.2)\n",
      "Collecting scikit-learn<1,>=0.19\n",
      "  Downloading scikit-learn-0.24.2.tar.gz (7.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[41 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Error in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "  \u001b[31m   \u001b[0m AssertionError:\n",
      "  \u001b[31m   \u001b[0m Partial import of sklearn during the build process.\n",
      "  \u001b[31m   \u001b[0m <string>:116: DeprecationWarning:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "  \u001b[31m   \u001b[0m   of the deprecation of `distutils` itself. It will be removed for\n",
      "  \u001b[31m   \u001b[0m   Python >= 3.12. For older Python versions it will remain present.\n",
      "  \u001b[31m   \u001b[0m   It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "  \u001b[31m   \u001b[0m   For more details, see:\n",
      "  \u001b[31m   \u001b[0m     https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/36/ytfw56yd11s17csdmhvyggd40000gn/T/pip-install-lyh2zyxb/scikit-learn_fd362b80f2874837a32a6cb4f1a91b3d/sklearn/_build_utils/__init__.py\", line 27, in _check_cython_version\n",
      "  \u001b[31m   \u001b[0m     import Cython\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'Cython'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 351, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 333, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 152, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/setuptools/build_meta.py\", line 377, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/setuptools/build_meta.py\", line 482, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super(_BuildMetaLegacyBackend,\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/setuptools/build_meta.py\", line 335, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 301, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 297, in setup_package\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/site-packages/numpy/distutils/core.py\", line 135, in setup\n",
      "  \u001b[31m   \u001b[0m     config = configuration()\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 186, in configuration\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/36/ytfw56yd11s17csdmhvyggd40000gn/T/pip-install-lyh2zyxb/scikit-learn_fd362b80f2874837a32a6cb4f1a91b3d/sklearn/_build_utils/__init__.py\", line 30, in _check_cython_version\n",
      "  \u001b[31m   \u001b[0m     raise ModuleNotFoundError(message) from e\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: Please install Cython with a version >= 0.28.5 in order to build a scikit-learn from source.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hCollecting textdistance\n",
      "  Downloading textdistance-4.5.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: textdistance\n",
      "Successfully installed textdistance-4.5.0\n",
      "zsh:1: no matches found: ./drive/MyDrive/Adapting-OCR-master/*\n"
     ]
    }
   ],
   "source": [
    "#@title installing sample data generator\n",
    "\n",
    "!python --version\n",
    "\n",
    "!pip install trdg\n",
    "!pip3 install Pillow\n",
    "!pip3 install torch_utils\n",
    "!pip3 install torchvision\n",
    "!pip3 install pytorch_wrapper\n",
    "!pip3 install textdistance\n",
    "!cp -r ./drive/MyDrive/Adapting-OCR-master/* ./\n",
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQFK1dJeqzjm",
    "outputId": "411fb54d-3a83-4c8a-eb71-f7186df232fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: data/train/*\n",
      "zsh:1: no matches found: data/test/*\n",
      "zsh:1: command not found: trdg\n",
      "zsh:1: command not found: trdg\n"
     ]
    }
   ],
   "source": [
    "#@title Generating sample data\n",
    "!rm data/train/*\n",
    "!rm data/test/*\n",
    "!trdg -i words.txt -c 20000 --output_dir data/train -ft fonts/din1451alt.ttf\n",
    "!trdg -i words.txt -c 256 --output_dir data/test -ft fonts/din1451alt.ttf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ueLbWEY1S4_6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lmdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlmdb\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lmdb'"
     ]
    }
   ],
   "source": [
    "#@title Importing libraries\n",
    "\n",
    "# Source code from https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html#setting-up-the-data\n",
    "\n",
    "# Install missing dependencies:\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import six\n",
    "import random\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "import logging\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from src.utils.utils import AverageMeter, Eval, OCRLabelConverter\n",
    "from src.utils.utils import EarlyStopping, gmkdir\n",
    "from src.optim.optimizer import STLR\n",
    "from src.utils.utils import gaussian\n",
    "from tqdm import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcAFfCfqcnax"
   },
   "outputs": [],
   "source": [
    "#@title Dataset\n",
    "\n",
    "# Source code from https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html#setting-up-the-data\n",
    "\n",
    "class SynthDataset(Dataset):\n",
    "    def __init__(self, opt):\n",
    "        super(SynthDataset, self).__init__()\n",
    "        self.path = os.path.join(opt['path'], opt['imgdir'])\n",
    "        self.images = os.listdir(self.path)\n",
    "        self.nSamples = len(self.images)\n",
    "        f = lambda x: os.path.join(self.path, x)\n",
    "        self.imagepaths = list(map(f, self.images))\n",
    "       \ttransform_list =  [transforms.Grayscale(1),\n",
    "                            transforms.ToTensor(), \n",
    "                            transforms.Normalize((0.5,), (0.5,))]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "        self.collate_fn = SynthCollator()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert index <= len(self), 'index range error'\n",
    "        imagepath = self.imagepaths[index]\n",
    "        imagefile = os.path.basename(imagepath)\n",
    "        img = Image.open(imagepath)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        item = {'img': img, 'idx':index}\n",
    "        item['label'] = imagefile.split('_')[0]\n",
    "        return item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioH9WdBvc5ET"
   },
   "outputs": [],
   "source": [
    "#@title Synth collator\n",
    "\n",
    "# Source code from https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html#setting-up-the-data\n",
    "\n",
    "class SynthCollator(object):\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        width = [item['img'].shape[2] for item in batch]\n",
    "        indexes = [item['idx'] for item in batch]\n",
    "        imgs = torch.ones([len(batch), batch[0]['img'].shape[0], batch[0]['img'].shape[1], \n",
    "                           max(width)], dtype=torch.float32)\n",
    "        for idx, item in enumerate(batch):\n",
    "            try:\n",
    "                imgs[idx, :, :, 0:item['img'].shape[2]] = item['img']\n",
    "            except:\n",
    "                print(imgs.shape)\n",
    "        item = {'img': imgs, 'idx':indexes}\n",
    "        if 'label' in batch[0].keys():\n",
    "            labels = [item['label'] for item in batch]\n",
    "            item['label'] = labels\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5pOYe9ksePV"
   },
   "source": [
    "#Defining our Model\n",
    "\n",
    "Architecture proposed by [B. Shi et al.].\n",
    "\n",
    "![image.png](https://deepayan137.github.io/blog/images/crnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_v0Oi5Itd7n"
   },
   "outputs": [],
   "source": [
    "#@title Convolutional RNN layer & bidir. LSTM layer\n",
    "\n",
    "# Source code from https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html#setting-up-the-data\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "    def forward(self, input):\n",
    "        self.rnn.flatten_parameters()\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, opt, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        assert opt['imgH'] % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = opt['nChannels'] if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential()\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(opt['nHidden']*2, opt['nHidden'], opt['nHidden']),\n",
    "            BidirectionalLSTM(opt['nHidden'], opt['nHidden'], opt['nClasses']))\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "        output = output.transpose(1,0) #Tbh to bth\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCs5RRMG1QG8"
   },
   "source": [
    "#The CTC Loss\n",
    "\n",
    "CTC was proposed by [A. Graves et al.].\n",
    "We don't need exasct alignment between input and output.\n",
    "The CTC layer computes a score with all possible alignments of the target label.\n",
    "The OCR is trained to maximize the sum of these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCSq8JZ71ESr"
   },
   "outputs": [],
   "source": [
    "#@title The CTC Loss\n",
    "\n",
    "# Code by Jerin Philip\n",
    "# https://jerinphilip.github.io/\n",
    "\n",
    "class CustomCTCLoss(torch.nn.Module):\n",
    "    # T x B x H => Softmax on dimension 2\n",
    "    def __init__(self, dim=2):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.ctc_loss = torch.nn.CTCLoss(reduction='mean', zero_infinity=True)\n",
    "\n",
    "    def forward(self, logits, labels,\n",
    "            prediction_sizes, target_sizes):\n",
    "        EPS = 1e-7\n",
    "        loss = self.ctc_loss(logits, labels, prediction_sizes, target_sizes)\n",
    "        loss = self.sanitize(loss)\n",
    "        return self.debug(loss, logits, labels, prediction_sizes, target_sizes)\n",
    "    \n",
    "    def sanitize(self, loss):\n",
    "        EPS = 1e-7\n",
    "        if abs(loss.item() - float('inf')) < EPS:\n",
    "            return torch.zeros_like(loss)\n",
    "        if math.isnan(loss.item()):\n",
    "            return torch.zeros_like(loss)\n",
    "        return loss\n",
    "\n",
    "    def debug(self, loss, logits, labels,\n",
    "            prediction_sizes, target_sizes):\n",
    "        if math.isnan(loss.item()):\n",
    "            print(\"Loss:\", loss)\n",
    "            print(\"logits:\", logits)\n",
    "            print(\"labels:\", labels)\n",
    "            print(\"prediction_sizes:\", prediction_sizes)\n",
    "            print(\"target_sizes:\", target_sizes)\n",
    "            raise Exception(\"NaN loss obtained. But why?\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJZYX3YF5JuV"
   },
   "outputs": [],
   "source": [
    "#@title Training loop\n",
    "\n",
    "class OCRTrainer(object):\n",
    "    def __init__(self, opt):\n",
    "        super(OCRTrainer, self).__init__()\n",
    "        self.data_train = opt['data_train']\n",
    "        self.data_val = opt['data_val']\n",
    "        self.model = opt['model']\n",
    "        self.criterion = opt['criterion']\n",
    "        self.optimizer = opt['optimizer']\n",
    "        self.schedule = opt['schedule']\n",
    "        self.converter = OCRLabelConverter(opt['alphabet'])\n",
    "        self.evaluator = Eval()\n",
    "        print('Scheduling is {}'.format(self.schedule))\n",
    "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=opt['epochs'])\n",
    "        self.batch_size = opt['batch_size']\n",
    "        self.count = opt['epoch']\n",
    "        self.epochs = opt['epochs']\n",
    "        self.cuda = opt['cuda']\n",
    "        self.collate_fn = opt['collate_fn']\n",
    "        self.init_meters()\n",
    "\n",
    "    def init_meters(self):\n",
    "        self.avgTrainLoss = AverageMeter(\"Train loss\")\n",
    "        self.avgTrainCharAccuracy = AverageMeter(\"Train Character Accuracy\")\n",
    "        self.avgTrainWordAccuracy = AverageMeter(\"Train Word Accuracy\")\n",
    "        self.avgValLoss = AverageMeter(\"Validation loss\")\n",
    "        self.avgValCharAccuracy = AverageMeter(\"Validation Character Accuracy\")\n",
    "        self.avgValWordAccuracy = AverageMeter(\"Validation Word Accuracy\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits.transpose(1, 0)\n",
    "\n",
    "    def loss_fn(self, logits, targets, pred_sizes, target_sizes):\n",
    "        loss = self.criterion(logits, targets, pred_sizes, target_sizes)\n",
    "        return loss\n",
    "\n",
    "    def step(self):\n",
    "        self.max_grad_norm = 0.05\n",
    "        clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def schedule_lr(self):\n",
    "        if self.schedule:\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def _run_batch(self, batch, report_accuracy=False, validation=False):\n",
    "        input_, targets = batch['img'], batch['label']\n",
    "        targets, lengths = self.converter.encode(targets)\n",
    "        logits = self.forward(input_)\n",
    "        logits = logits.contiguous().cpu()\n",
    "        logits = torch.nn.functional.log_softmax(logits, 2)\n",
    "        T, B, H = logits.size()\n",
    "        pred_sizes = torch.LongTensor([T for i in range(B)])\n",
    "        targets= targets.view(-1).contiguous()\n",
    "        loss = self.loss_fn(logits, targets, pred_sizes, lengths)\n",
    "        if report_accuracy:\n",
    "            probs, preds = logits.max(2)\n",
    "            preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "            sim_preds = self.converter.decode(preds.data, pred_sizes.data, raw=False)\n",
    "            ca = np.mean((list(map(self.evaluator.char_accuracy, list(zip(sim_preds, batch['label']))))))\n",
    "            wa = np.mean((list(map(self.evaluator.word_accuracy, list(zip(sim_preds, batch['label']))))))\n",
    "        return loss, ca, wa\n",
    "\n",
    "    def run_epoch(self, validation=False):\n",
    "        if not validation:\n",
    "            loader = self.train_dataloader()\n",
    "            pbar = tqdm(loader, desc='Epoch: [%d]/[%d] Training'%(self.count, \n",
    "                self.epochs), leave=True)\n",
    "            self.model.train()\n",
    "        else:\n",
    "            loader = self.val_dataloader()\n",
    "            pbar = tqdm(loader, desc='Validating', leave=True)\n",
    "            self.model.eval()\n",
    "        outputs = []\n",
    "        for batch_nb, batch in enumerate(pbar):\n",
    "            if not validation:\n",
    "                output = self.training_step(batch)\n",
    "            else:\n",
    "                output = self.validation_step(batch)\n",
    "            pbar.set_postfix(output)\n",
    "            outputs.append(output)\n",
    "        self.schedule_lr()\n",
    "        if not validation:\n",
    "            result = self.train_end(outputs)\n",
    "        else:\n",
    "            result = self.validation_end(outputs)\n",
    "        return result\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss, ca, wa = self._run_batch(batch, report_accuracy=True)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.step()\n",
    "        output = OrderedDict({\n",
    "            'loss': abs(loss.item()),\n",
    "            'train_ca': ca.item(),\n",
    "            'train_wa': wa.item()\n",
    "            })\n",
    "        return output\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss, ca, wa = self._run_batch(batch, report_accuracy=True, validation=True)\n",
    "        output = OrderedDict({\n",
    "            'val_loss': abs(loss.item()),\n",
    "            'val_ca': ca.item(),\n",
    "            'val_wa': wa.item()\n",
    "            })\n",
    "        return output\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # logging.info('training data loader called')\n",
    "        loader = torch.utils.data.DataLoader(self.data_train,\n",
    "                batch_size=self.batch_size,\n",
    "                collate_fn=self.collate_fn,\n",
    "                shuffle=True)\n",
    "        return loader\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        # logging.info('val data loader called')\n",
    "        loader = torch.utils.data.DataLoader(self.data_val,\n",
    "                batch_size=self.batch_size,\n",
    "                collate_fn=self.collate_fn)\n",
    "        return loader\n",
    "\n",
    "    def train_end(self, outputs):\n",
    "        for output in outputs:\n",
    "            self.avgTrainLoss.add(output['loss'])\n",
    "            self.avgTrainCharAccuracy.add(output['train_ca'])\n",
    "            self.avgTrainWordAccuracy.add(output['train_wa'])\n",
    "\n",
    "        train_loss_mean = abs(self.avgTrainLoss.compute())\n",
    "        train_ca_mean = self.avgTrainCharAccuracy.compute()\n",
    "        train_wa_mean = self.avgTrainWordAccuracy.compute()\n",
    "\n",
    "        result = {'train_loss': train_loss_mean, 'train_ca': train_ca_mean,\n",
    "        'train_wa': train_wa_mean}\n",
    "        # result = {'progress_bar': tqdm_dict, 'log': tqdm_dict, 'val_loss': train_loss_mean}\n",
    "        return result\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        for output in outputs:\n",
    "            self.avgValLoss.add(output['val_loss'])\n",
    "            self.avgValCharAccuracy.add(output['val_ca'])\n",
    "            self.avgValWordAccuracy.add(output['val_wa'])\n",
    "\n",
    "        val_loss_mean = abs(self.avgValLoss.compute())\n",
    "        val_ca_mean = self.avgValCharAccuracy.compute()\n",
    "        val_wa_mean = self.avgValWordAccuracy.compute()\n",
    "\n",
    "        result = {'val_loss': val_loss_mean, 'val_ca': val_ca_mean,\n",
    "        'val_wa': val_wa_mean}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okmArj4xAa2V"
   },
   "outputs": [],
   "source": [
    "#@title Putting everything together\n",
    "\n",
    "# Source code from https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html\n",
    "# Under MIT license\n",
    "\n",
    "class Learner(object):\n",
    "    def __init__(self, model, optimizer, savepath=None, resume=False):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.savepath = os.path.join(savepath, 'best.ckpt')\n",
    "        self.cuda = torch.cuda.is_available() \n",
    "        self.cuda_count = torch.cuda.device_count()\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        self.epoch = 0\n",
    "        if self.cuda_count > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.best_score = None\n",
    "        if resume and os.path.exists(self.savepath):\n",
    "            self.checkpoint = torch.load(self.savepath)\n",
    "            self.epoch = self.checkpoint['epoch']\n",
    "            self.best_score=self.checkpoint['best']\n",
    "            self.load()\n",
    "        else:\n",
    "            print('checkpoint does not exist')\n",
    "\n",
    "    def fit(self, opt):\n",
    "        opt['cuda'] = self.cuda\n",
    "        opt['model'] = self.model\n",
    "        opt['optimizer'] = self.optimizer\n",
    "        logging.basicConfig(filename=\"%s/%s.csv\" %(opt['log_dir'], opt['name']), level=logging.INFO)\n",
    "        self.saver = EarlyStopping(self.savepath, patience=15, verbose=True, best_score=self.best_score)\n",
    "        opt['epoch'] = self.epoch\n",
    "        trainer = OCRTrainer(opt)\n",
    "        \n",
    "        for epoch in range(opt['epoch'], opt['epochs']):\n",
    "            train_result = trainer.run_epoch()\n",
    "            val_result = trainer.run_epoch(validation=True)\n",
    "            trainer.count = epoch\n",
    "            info = '%d, %.6f, %.6f, %.6f, %.6f, %.6f, %.6f'%(epoch, train_result['train_loss'], \n",
    "                val_result['val_loss'], train_result['train_ca'],  val_result['val_ca'],\n",
    "                train_result['train_wa'], val_result['val_wa'])\n",
    "            logging.info(info)\n",
    "            self.val_loss = val_result['val_loss']\n",
    "            print(self.val_loss)\n",
    "            if self.savepath:\n",
    "                self.save(epoch)\n",
    "            if self.saver.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    def load(self):\n",
    "        print('Loading checkpoint at {} trained for {} epochs'.format(self.savepath, self.checkpoint['epoch']))\n",
    "        self.model.load_state_dict(self.checkpoint['state_dict'])\n",
    "        if 'opt_state_dict' in self.checkpoint.keys():\n",
    "            print('Loading optimizer')\n",
    "            self.optimizer.load_state_dict(self.checkpoint['opt_state_dict'])\n",
    "\n",
    "    def save(self, epoch):\n",
    "        self.saver(self.val_loss, epoch, self.model, self.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUZsGlXhBX1z",
    "outputId": "c3db9035-ec74-4ca3-9176-514259395653"
   },
   "outputs": [],
   "source": [
    "#@title Learning\n",
    "\n",
    "# Source code from https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html\n",
    "# MIT license\n",
    "\n",
    "alphabet = \"\"\"Only thewigsofrcvdampbkuq.$A-210xT5'MDL,RYHJ\"ISPWENj&BC93VGFKz();#:!7U64Q8?+*ZX/%\"\"\"\n",
    "args = {\n",
    "    'name':'exp1',\n",
    "    'path':'data',\n",
    "    'imgdir': 'train',\n",
    "    'imgH':32,\n",
    "    'nChannels':1,\n",
    "    'nHidden':256,\n",
    "    'nClasses':len(alphabet),\n",
    "    'lr':0.001,\n",
    "    'epochs':4,\n",
    "    'batch_size':32,\n",
    "    'save_dir':'checkpoints',\n",
    "    'log_dir':'logs',\n",
    "    'resume':False,\n",
    "    'cuda':False,\n",
    "    'schedule':False\n",
    "    \n",
    "}\n",
    "\n",
    "data = SynthDataset(args)\n",
    "args['collate_fn'] = SynthCollator()\n",
    "train_split = int(0.8*len(data))\n",
    "val_split = len(data) - train_split\n",
    "args['data_train'], args['data_val'] = random_split(data, (train_split, val_split))\n",
    "print('Traininig Data Size:{}\\nVal Data Size:{}'.format(\n",
    "    len(args['data_train']), len(args['data_val'])))\n",
    "args['alphabet'] = alphabet\n",
    "model = CRNN(args)\n",
    "args['criterion'] = CustomCTCLoss()\n",
    "savepath = os.path.join(args['save_dir'], args['name'])\n",
    "gmkdir(savepath)\n",
    "gmkdir(args['log_dir'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "learner = Learner(model, optimizer, savepath=savepath, resume=args['resume'])\n",
    "learner.fit(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vnjn8zG-CUQa"
   },
   "source": [
    "#Evaluation and testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFEU24AqChrG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_accuracy(args):\n",
    "    loader = torch.utils.data.DataLoader(args['data'],\n",
    "                batch_size=args['batch_size'],\n",
    "                collate_fn=args['collate_fn'])\n",
    "    model = args['model']\n",
    "    model.eval()\n",
    "    converter = OCRLabelConverter(args['alphabet'])\n",
    "    evaluator = Eval()\n",
    "    labels, predictions, images = [], [], []\n",
    "    for iteration, batch in enumerate(tqdm(loader)):\n",
    "        input_, targets = batch['img'].to(device), batch['label']\n",
    "        images.extend(input_.squeeze().detach())\n",
    "        labels.extend(targets)\n",
    "        targets, lengths = converter.encode(targets)\n",
    "        logits = model(input_).transpose(1, 0)\n",
    "        logits = torch.nn.functional.log_softmax(logits, 2)\n",
    "        logits = logits.contiguous().cpu()\n",
    "        T, B, H = logits.size()\n",
    "        pred_sizes = torch.LongTensor([T for i in range(B)])\n",
    "        probs, pos = logits.max(2)\n",
    "        pos = pos.transpose(1, 0).contiguous().view(-1)\n",
    "        sim_preds = converter.decode(pos.data, pred_sizes.data, raw=False)\n",
    "        predictions.extend(sim_preds)\n",
    "        \n",
    "#     make_grid(images[:10], nrow=2)\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    columns = 4\n",
    "    rows = 5\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img = images[i]\n",
    "        img = (img - img.min())/(img.max() - img.min())\n",
    "        img = np.array(img * 255.0, dtype=np.uint8)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.title(predictions[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    ca = np.mean((list(map(evaluator.char_accuracy, list(zip(predictions, labels))))))\n",
    "    wa = np.mean((list(map(evaluator.word_accuracy_line, list(zip(predictions, labels))))))\n",
    "    return ca, wa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "r2NqixpbCl5b",
    "outputId": "04450fd2-e040-47d3-c5c1-d2800f16cd63"
   },
   "outputs": [],
   "source": [
    "args['imgdir'] = 'test'\n",
    "args['data'] = SynthDataset(args)\n",
    "resume_file = os.path.join(args['save_dir'], args['name'], 'best.ckpt')\n",
    "if os.path.isfile(resume_file):\n",
    "    print('Loading model %s'%resume_file)\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    args['model'] = model\n",
    "    ca, wa = get_accuracy(args)\n",
    "    print(\"Character Accuracy: %.2f\\nWord Accuracy: %.2f\"%(ca, wa))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(save_file))\n",
    "    print('Exiting')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
