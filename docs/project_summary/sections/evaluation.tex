\section{Evaluation}

\todo[inline]{Write this section, actualize it to what we actually did.}

\todo[inline]{Write about Precision/Recall, etc.}

We will consider different cases depending on the difficulty of the given image,
which will be determined based on how well our solution performs under
the given (visual) setting. Based on this, we will categorize these cases by
perceived difficulty, and show examples.

These are some of the settings we expect to make \ac{ALPR} more
difficult:\todo[inline]{Create these comparisons, plot them in a figure.}
\begin{itemize}
    \item Direct sunlight 
    \item Partial occlusion of the license plate 
    \item Miscellaneous weather effects such as rain or fog
    \item Small size of the licence plate (i.e. the object is further away)
\end{itemize}

We will examine which of these settings introduce the most perceived noise, thus
decreasing the effectiveness of our solution.

Other than these, -- as is the case with all learning-based methods, -- there is
an inherent uncertainty on the generalization capabilities of our solution.
After training and testing our solution on a predefined dataset, the real trial
will be generalizing to photos we never encountered, as these images will be
out-of-distribution for sure. Thus, we plan to finish our project with
evaluating our solution \textit{in the wild}, measuring its robustness on
real-life data.

\todo[inline]{Add image results.}
